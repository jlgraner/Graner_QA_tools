{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing out creating a gif from nii data in python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from PIL import Image as pImage\n",
    "import os, sys\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grayscale_conv(input_array):\n",
    "    gs_array = 255*(input_array/input_array.max())\n",
    "    gs_array = np.rint(gs_array)\n",
    "    return gs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_picture(input_array):\n",
    "    #The input will be an array as read by nib\n",
    "    #The output will be a PIL Image object\n",
    "    #gs_array = 255*(input_array/input_array.max())\n",
    "    #gs_array = np.rint(gs_array)\n",
    "    pil_image = pImage.fromarray(input_array)\n",
    "    #Rotate the image (if needed) so the longest side is the width\n",
    "    if pil_image.size[0] == max(pil_image.size):\n",
    "        output_pimage = pil_image\n",
    "    else:\n",
    "        output_pimage = pil_image.rotate(90,expand=1)\n",
    "    #Convert the image mode to \"LA\" for writing\n",
    "    output_pimage = output_pimage.convert(mode=\"LA\")\n",
    "    return output_pimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = '/mnt/keoki/experiments2/Graner/Data/Graner_QA_tools/test_data/fmri/fmri_test_input.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image with nibabel; get image data\n",
    "input_image = nib.load(test_data)\n",
    "input_data = input_image.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create slice-wise sections of data\n",
    "#Pick out the center slice of each time point for each dimension\n",
    "#(We don't need to know which dimension is which since we're doing all of them)\n",
    "input_dims = input_data.shape\n",
    "center_x = round(input_dims[0] / 2.0)\n",
    "center_y = round(input_dims[1] / 2.0)\n",
    "center_z = round(input_dims[2] / 2.0)\n",
    "time_points = input_dims[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the center slice of each dimension\n",
    "center_x_image = input_data[center_x, :, :, :]\n",
    "center_y_image = input_data[:, center_y, :, :]\n",
    "center_z_image = input_data[:, :, center_z, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_z_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescale each group of center slices to 0-255\n",
    "#This process also squeezes the arrays down to 3 dimensions\n",
    "center_x_image = _grayscale_conv(center_x_image)\n",
    "center_y_image = _grayscale_conv(center_y_image)\n",
    "center_z_image = _grayscale_conv(center_z_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_slice=center_x_image[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(one_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_rows = np.zeros((128, 5))\n",
    "tracker_rows[:]=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_rows.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 73)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.concatenate((one_slice, tracker_rows), axis=1)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image = pImage.fromarray(one_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e6c08279524f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "pil_image.data[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each of the three dimensions, for each timepoint in that dimension,\n",
    "#extract the slice and create a formatted PIL Image version of it\n",
    "dim_count = 0\n",
    "for subset in [center_x_image, center_y_image, center_z_image]:\n",
    "    slice_files = []\n",
    "    #Create a temporary png file of the center slice at each timepoint\n",
    "    for slice_num in range(subset.shape[2]):\n",
    "        this_slice = subset[:,:,slice_num]\n",
    "        slice_to_write = _format_picture(this_slice)\n",
    "        slice_to_write.save(os.path.join(os.getcwd(), 'temp_slice_{}_{}.png'.format(dim_count,slice_num)))\n",
    "        slice_files.append(os.path.join(os.getcwd(), 'temp_slice_{}_{}.png'.format(dim_count,slice_num)))\n",
    "    #Create a gif of the center slice pictures\n",
    "    images = []\n",
    "    for filename in slice_files:\n",
    "        images.append(imageio.imread(filename))\n",
    "    output_gif = os.path.join(os.getcwd(), 'center_slice_gif_{}.gif'.format(dim_count))\n",
    "    imageio.mimsave(output_gif, images, duration=0.2)\n",
    "    dim_count = dim_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = np.arange(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    3.,    6.,    8.,   11.,   13.,   16.,   18.,   21.,\n",
       "         24.,   26.,   29.,   31.,   34.,   36.,   39.,   41.,   44.,\n",
       "         47.,   49.,   52.,   54.,   57.,   59.,   62.,   64.,   67.,\n",
       "         70.,   72.,   75.,   77.,   80.,   82.,   85.,   88.,   90.,\n",
       "         93.,   95.,   98.,  100.,  103.,  105.,  108.,  111.,  113.,\n",
       "        116.,  118.,  121.,  123.,  126.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil((thing)*(128.0/50.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_add = np.zeros((128,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_add[0:6,:] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 255.,  255.,  255.,  255.,  255.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_to_add[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 128)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rot90(rows_to_add).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
